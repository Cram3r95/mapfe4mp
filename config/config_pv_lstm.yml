## LSTM based Encoder-Decoder Position-Velocity configuration file

# Dataset & HW

use_gpu: 1
device_gpu: 0 # Default CUDA device
dataset_name: argoverse_motion_forecasting_dataset
dataset:
    path: data/datasets/argoverse/motion-forecasting/
    split: "train"
    batch_size: 1024
    num_workers: 0
    start_from_percentage: 0.0 # By default, 0. If you want to analize a particular bunch of files (e.g. from 25 % to 50 %)
                               # then write here 0.25 and in split_percentage 0.25
    split_percentage: 1.0 # % of the dataset (0-1)
    extra_data_train: -1.0 # % (0-1) of the val split is used for training too. Remaining files are used for validation
    shuffle: True 
    data_augmentation: True # Rotation, Swapping, Dropout, Gaussian noise
    class_balance: -1.0 # % of straight trajectories (considering the AGENT). Remaining % are curved trajectories
                        # (again, considering the AGENT). -1.0 if no class balance is used (get_item takes the corresponding
                        # sequence regardless if it is straight or curved)
    preprocess_data: False
    save_data: False

# Model hyperparameters

optim_parameters:
    g_learning_rate: 1.0e-3
    g_weight_decay: 0
hyperparameters:
    output_single_agent: True

    num_modes: 6 # Multimodality
    obs_origin: 20 # This frame will be the origin, tipically the first observation (1) or last observation 
                   # (obs_len) of the AGENT (object to be predicted in Argoverse 1.0). Note that in the code
                   # it will be 0 and 19 respectively
    obs_len: &obs_len 20 
    pred_len: &pred_len 30 # Must be 0 for the split test since we do not have the predictions of the agents
                           # Only the observations (0 to obs_len-1 past observations)
    distance_threshold: 40 # It depends on a statistical study (see get_sequences_as_array function), 
                           # where we determine which is the optimal distance for which most agents
                           # are observed for our AGENT
    
    num_epochs: 100
    print_every: 50
    checkpoint_name: "0"                      
    checkpoint_val_percentage: 0.1 # 0.1 # (0 - 1) Check accuracy in validation split every
                                    # checkpoint_val_percentage * total_num_iterations
    checkpoint_train_percentage: 0.1 # 0.2 # (0 - 1)
    num_samples_check: 5000 # Check a maximum of num_samples_check in the check_accuracy function

    loss_type_g: "mse_w" # (mse|mse_w), nll, (mse|mse_w)+nll, (mse|mse_w)+fa 
    loss_ade_weight: 1.0
    loss_ade_rel_weight: 1.0
    loss_fde_weight: 1.0
    loss_fde_rel_weight: 1.0
    loss_nll_weight: 1.0
    loss_fa_weight: 1

    lr_scheduler: True
    lr_decay_factor: 0.65
    lr_epoch_percentage_patience: 0.1 # (0-N) E.g. If 0.05 -> the patience will be the 5 % of the total epochs
    
    g_steps: 1
    clipping_threshold_g: 1.1
    
    save_root_dir: "save/argoverse"
    exp_name: "no concat features" # If no specific exp_name is used, fill with current day and hour
    output_dir: # To be filled in the code (save_root_dir/model_name/split_percentage/exp)
    checkpoint_start_from:
    exp_description: "Test motion prediction using position-velocity encoding"
    tensorboard_active: True

# Model

model:
    name: "pv_lstm"
    adversarial_training: False
    generator:
        encoder_lstm:
            dropout: &dropout 0.2
        decoder_lstm:
            dropout: *dropout


